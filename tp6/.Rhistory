id = ID,
family = binomial,
data = data,
corstr = "unstructured")
QIC(m_simcomp, m_ar1, m_desest)
m1 <- glmmTMB(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración + (1|ID),
family = binomial,
data = data)
library(pander) # instalar
library(reshape2)
library(GGally)
library(dplyr)
library(ggplot2)
library(ggeffects)
library(glmmTMB)
library(geepack)
library(DHARMa)
library(sjPlot)
library(performance)
library(car)
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),contrast = list(infer = c(TRUE, TRUE))))
m1 <- glmmTMB(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración + (1|ID),
family = binomial,
data = data)
sim <- simulateResiduals(m1, 10000)
plot(sim)
id <- data.frame(alfai = ranef(m1)$cond$ID$'(Intercept)')
test_de_shapiro <- shapiro.test(id$alfai)
pander(round(Anova(m1), 4), caption = "(\\#tab:modelos-con-duracion-3) Anova de tipo 2 para el modelo con el outlier en Duración")
m_simcomp <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "exchangeable")
m_ar1 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "ar1")
m_desest <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "unstructured")
pander(round(QIC(m_simcomp, m_ar1, m_desest), 4), caption = "(\\#tab:modeloGEE) Comparación de modelos utilizando GEE para 3 matrices de correlación: simetría compuesta, autoregresiva de orden 1 y desestructurada")
# Esto también sucede sin incluir a la covariable Duración
m_simcomp2 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión,
id = ID,
family = binomial,
data = data,
corstr = "exchangeable")
m_ar1_2 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión,
id = ID,
family = binomial,
data = data,
corstr = "ar1")
m_desest2<- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión,
id = ID,
family = binomial,
data = data,
corstr = "unstructured")
QIC(m_simcomp2, m_ar1_2, m_desest2)
setwd("C:/Users/snpre/Documentos/Carrera/Biometria II/tp6")
setwd("~/Carrera/Biometria II/tp6")
setwd("C:/Users/snpre/Documents/Carrera/Biometria II/tp6")
datos <- read.csv("colembolos2.csv", header = T, sep=";", dec=".", stringsAsFactors = T)
str(datos)
# Exploramos
summary(datos)
# ID va de 1 a 120
# Esta balanceado: hay 40 de cada especie
head(datos)
library(ggplot2)
ggplot(datos, aes(Especie, Riqueza)) +
geom_boxplot() +
geom_jitter(width = 0.1, alpha=0.3)
library(dplyr)
library(dplyr)
resumen <- datos %>%
group_by(Especie) %>%
summarise(media = mean(Riqueza),
sd = sd(Riqueza),
min =min(Riqueza),
var=var(Riqueza),# Agregue varianza para compararla con la media pues Poisson
max =max(Riqueza))
resumen
m1 <- glm(Riqueza ~ Especie, data=datos, family=poisson) # puede dar problemas de convergencia a veces
summary(m1)
# con glmmTMB
# install.packages("glmmTMB", dependencies = TRUE)
library(glmmTMB) # es buenisima
m1b <- glmmTMB(Riqueza ~ Especie, data=datos, family=poisson)
summary(m1b)
# Dispersion
# Chequeamos parametros de dispersion
sum(resid(m1, type="pearson")^2)/m1$df.residual # cercano a 1, re bien
library(performance)
check_overdispersion(m1) # No overdispersion detected.
# significancia 'global'
drop1(m1, test = "Chisq") # mayor devianza pero modelo (medida de falta de ajuste)
m0<-glmmTMB(Riqueza ~ 1, data=datos, family=poisson)
library(car)
Anova(m1) # deberia dar exactamente lo mismo !
Anova(m0,m1) # NO lo pude correr, ver en casa
library(car)
Anova(m1) # deberia dar exactamente lo mismo !
Anova(m0,m1) # NO lo pude correr, ver en casa
Anova(m0,m1b) # NO lo pude correr, ver en casa
anova(m0,m1) # NO lo pude correr, ver en casa
# coeficientes del modelo
summary(m1)# en que escala estan los coeficientes?
# Devianza explicada
((m1$null.deviance-m1$deviance)/m1$null.deviance)*100 # 39
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),
contrast = list(infer = c(TRUE, TRUE)))) # opciones de seteo de las opciones de salida
# Escala del predictor lineal - Logaritmica
compPL <- emmeans(m1, pairwise ~ Especie) # Tukey por default
compPL
datos <- read.delim("roadkills.txt")
#### seleccionamos las variables de interes (segun enunciado)
datos <- subset(datos[,c(5,7,9,11,12,14,15,17,19,20)])
names(datos)
#### aplicamos log d ela VR, para descriptiva
datos$ln_TOT.N <- log(datos$TOT.N)
#### grafico de dispersion entre pares de variables y coeficiente de correlacion
library(GGally)
# PARA VER SI SE CUMPLE LA LINEALIDAD EN LA ESCALA DEL PREDICTOR LINEAL
ggpairs(datos,mapping = ggplot2::aes(),lower = list(continuous = wrap("smooth", alpha = 0.3, size=0.1),
discrete = "blank", combo="blank"),
diag = list(discrete="barDiag",
continuous = wrap("densityDiag", alpha=0.5 )),
upper = list(combo = wrap("box_no_facet", alpha=0.5),
continuous = wrap("cor", size=4, alignPercent=0.8))) +
theme(panel.grid.major = element_blank())
# Correlation matrix
corr_datos <- round(cor(datos[,2:10]), 2)
print(corr_datos)
# ejemplo:
# var original (x)
range(datos$POLIC) # [1]  0.000 11.263
# aplica raiz (x)
datos$SQ.POLIC <- sqrt(datos$POLIC)
# raiz de la var original (x)
range(datos$SQ.POLIC) # [1] 0.000000 3.356039
# aplica raiz al resto:
datos$SQ.SHRUB <- sqrt(datos$SHRUB)
datos$SQ.WAT.RES <- sqrt(datos$WAT.RES)
datos$SQ.L.P.ROAD <- sqrt(datos$L.P.ROAD)
datos$SQ.D.WAT.COUR <- sqrt(datos$D.WAT.COUR)
#### Ajuste el modelo (aditivo con todas las predictoras incluidas) en R y evalúe los supuestos
m1 <- glm(TOT.N ~ OPEN.L + MONT.S + SQ.POLIC +D.PARK + SQ.SHRUB + SQ.WAT.RES +
L.WAT.C +SQ.L.P.ROAD + SQ.D.WAT.COUR, family = poisson,data = datos)
####
library(glmmTMB)
# se comeinza ajustando un modelo nulo (sin variables predictoras)
mnulo <- glmmTMB(TOT.N ~ 1, data = datos, family = nbinom2)
summary(mnulo) # sin predictoras
# evaluar la incorporacion de nuevas variables sobre "mnulo"
add1(mnulo, TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + D.PARK + SQ.SHRUB + SQ.WAT.RES + L.WAT.C +
SQ.L.P.ROAD + SQ.D.WAT.COUR, test="Chisq")
setwd("~/Carrera/Biometria II/Posit/4")
Datos  <- read.csv("BIOMASARATONES.csv", stringsAsFactors = T)
library(dplyr)
library(pastecs)
library(ggplot2)
library(ggcorrplot)
library(corrplot)
library(car) #
library(caret)
library(sjPlot)
library(faraway)
library(lm.beta)
library(MuMIn)
library(performance)
# m1
# modelo aditivo completo
m1 <- lm(ratones ~ lluvia+predadores+cobertura+semillas, Datos)
drop1(m1)
drop1(m1, test="F") # y agregando el test vemos la significacion de la disminución en la SC residual ( variabilidad no explicada) del modelo con una VE más y el reducido
drop1(m1, test="F")
View(m0)
View(m0)
View(Datos)
setwd("C:/Users/snpre/Documents/Carrera/Biometria II/tp6")
datos <- read.csv("colembolos2.csv", header = T, sep=";", dec=".", stringsAsFactors = T)
str(datos)
# Exploramos
summary(datos)
# ID va de 1 a 120
# Esta balanceado: hay 40 de cada especie
head(datos)
library(ggplot2)
ggplot(datos, aes(Especie, Riqueza)) +
geom_boxplot() +
geom_jitter(width = 0.1, alpha=0.3)
library(dplyr)
resumen <- datos %>%
group_by(Especie) %>%
summarise(media = mean(Riqueza),
sd = sd(Riqueza),
min =min(Riqueza),
var=var(Riqueza),# Agregue varianza para compararla con la media pues Poisson
max =max(Riqueza))
resumen
m1 <- glm(Riqueza ~ Especie, data=datos, family=poisson) # puede dar problemas de convergencia a veces
summary(m1)
# con glmmTMB
# install.packages("glmmTMB", dependencies = TRUE)
library(glmmTMB) # es buenisima
# con glmmTMB
# install.packages("glmmTMB", dependencies = TRUE)
library(glmmTMB) # es buenisima
m1b <- glmmTMB(Riqueza ~ Especie, data=datos, family=poisson)
summary(m1b)
# Dispersion
# Chequeamos parametros de dispersion
sum(resid(m1, type="pearson")^2)/m1$df.residual # cercano a 1, re bien
library(performance)
check_overdispersion(m1) # No overdispersion detected.
# significancia 'global'
drop1(m1, test = "Chisq") # mayor devianza peor modelo (medida de falta de ajuste)
m0<-glmmTMB(Riqueza ~ 1, data=datos, family=poisson)
Anova(m1) # deberia dar exactamente lo mismo !
# coeficientes del modelo
summary(m1)# en que escala estan los coeficientes?
# Devianza explicada
((m1$null.deviance-m1$deviance)/m1$null.deviance)*100 # 39
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),
contrast = list(infer = c(TRUE, TRUE)))) # opciones de seteo de las opciones de salida
# Escala del predictor lineal - Logaritmica
compPL <- emmeans(m1, pairwise ~ Especie) # Tukey por default
compPL
# Veo diferencias entre todos
# Escala de la variable respuesta
compVR <- emmeans(m1, pairwise ~ Especie, type="response") # Tukey por default
compVR
# calcular las medias estimadas en la escala de la variable respuesta, a partir del summary
# ayuda:
exp(coef(m1)) # me da e**beta0,  e**beta1, e**beta2
library(ggeffects)
estim<-ggpredict(m1, terms = c("Especie"))
estim
plot(estim, add.data = F)
aves <- read.table("aves.txt", header = T, stringsAsFactors = T)
aves <- read.table("aves.txt", header = T, stringsAsFactors = T)
# Exploramos
str(aves)
#'data.frame':	35 obs. of  3 variables:
#$ Ambiente : Factor w/ 2 levels "Metropol","Reserva": 1 1 1 1 1 1 1 1 1 1 ...
#$ Aves     : int  4 0 1 4 1 5 1 2 2 3 ...
#$ DurObserv: int  4 2 2 3 5 5 5 4 4 5 ...
summary(aves)
table(aves$Ambiente, useNA = "always")
#'data.frame':	35 obs. of  3 variables:
#$ Ambiente : Factor w/ 2 levels "Metropol","Reserva": 1 1 1 1 1 1 1 1 1 1 ...
#$ Aves     : int  4 0 1 4 1 5 1 2 2 3 ...
#$ DurObserv: int  4 2 2 3 5 5 5 4 4 5 ...
summary(aves)
#Damos vuelta los niveles (porque nos será conveniente para interpretar luego)
levels(aves$Ambiente)
aves$Ambiente <- factor(aves$Ambiente, levels = c("Reserva", "Metropol"))
levels(aves$Ambiente)
# calculamos la tasa de avistajes por minuto a partir del N de aves (para descriptiva)
aves$tasa_Aves <- aves$Aves / aves$DurObserv
# chequeamos data.frame
summary(aves)
str(aves)
head(aves)
library(ggplot2)
ggplot(aves, aes(Ambiente, tasa_Aves)) +
geom_boxplot() +
geom_jitter(width = 0.1, alpha=0.3, colour="blue")
# Pasamos la variable offset a logaritmo
aves$Log_DurObserv <- log(aves$DurObserv)
m1a <- glm(Aves~ Ambiente + offset(Log_DurObserv), data=aves, family=poisson)
summary(m1a)
#    Null deviance: 105.843  on 34  degrees of freedom
#Residual deviance:  42.655  on 33  degrees of freedom
# con glmmTMB
# install.packages("glmmTMB", dependencies = TRUE)
library(glmmTMB)
m1b <- glmmTMB(Aves~ Ambiente + offset(Log_DurObserv), data=aves, family=poisson)
summary(m1b)
# Dispersion
sum(resid(m1a, type="pearson")^2)/m1a$df.residual # 1.19 ojotaaa
library(performance)
check_overdispersion(m1a) # NO overdispersion detected todo OK
# Supuestos ####
# install.packages("DHARMa", dependencies = TRUE)
library(DHARMa)
sim <- simulateResiduals(m1a, n = 1000)
plot(sim)
# significancia 'global'
drop1(m1a, test = "Chisq")
# Devianza explicada
((m1a$null.deviance-m1a$deviance)/m1a$null.deviance)*100 #60%
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),
contrast = list(infer = c(TRUE, TRUE)))) # opciones de seteo de las opciones de salida
# Escala del predictor lineal
# si agrego offset =0  la tasa es de un minuto. Unidades del logaritmo. No se informa, si sirve para significancia
compPL <- emmeans(m1a, pairwise ~ Ambiente, offset = 0) # Tukey por default
compPL
# Escala de la variable respuesta
#  lo mismo, es por minuto. Aves obs por minuto, sin logaritmo
compVR <- emmeans(m1a, pairwise ~ Ambiente, type="response", offset = 0) # Tukey por default
compVR
# pero por default emmeans no pone offset = 0
# Si no seteamos offset ...
compVRSin_of <- emmeans(m1a, pairwise ~ Ambiente, type="response") #
compVRSin_of
#Observar que la diferencia entre incluir o no incluir offset=0 es:
ref_grid(m1a) # esto devuelve con lo que trabajo
# Toma el valor de Log_DurObserv = 1.4458
mean(aves$Log_DurObserv) # Aca vemos que es el promedio!!
library(ggeffects)
estim<-ggpredict(m1a, terms = c("Ambiente"))
estim
plot(estim, add.data = F)
estim<-ggpredict(m1a, offset=0, terms = c("Ambiente"))
estim
plot(estim, add.data = F)
estim<-ggpredict(m1a, offset=0, terms = c("Ambiente"))
estim
# lo siguiente no esta bien, ver
compVR <- emmeans(m1, pairwise ~ Especie, type="response", offset = log(60)) # Tukey por default
compVR
compVR
# Escala de la variable respuesta
#  lo mismo, es por minuto. Aves obs por minuto, sin logaritmo
compVR <- emmeans(m1a, pairwise ~ Ambiente, type="response", offset = 0) # Tukey por default
compVR
# lo siguiente no esta bien, ver
compVR60 <- emmeans(m1a, pairwise ~ Ambiente, type="response", offset = log(60)) # Tukey por default
compVR60
#d) Ajuste el modelo en R y evalúe los supuestos
# Hecho arriba
#e) En qué medida las reservas favorecen la conservación de aves nativas?. Informe la magnitud del efecto en escala de la variable respuesta.
compVR
2/0.585
rm(list=ls())
setwd("C:/Users/snpre/Documents/Carrera/Biometria II/tp6")
datos <- read.delim("roadkills.txt")
names(datos)
str(datos)
#### seleccionamos las variables de interes (segun enunciado)
datos <- subset(datos[,c(5,7,9,11,12,14,15,17,19,20)])
names(datos)
#### aplicamos log d ela VR, para descriptiva
datos$ln_TOT.N <- log(datos$TOT.N)
#### grafico de dispersion entre pares de variables y coeficiente de correlacion
library(GGally)
# PARA VER SI SE CUMPLE LA LINEALIDAD EN LA ESCALA DEL PREDICTOR LINEAL
ggpairs(datos,mapping = ggplot2::aes(),lower = list(continuous = wrap("smooth", alpha = 0.3, size=0.1), discrete = "blank", combo="blank"), diag = list(discrete="barDiag", continuous = wrap("densityDiag", alpha=0.5 )), upper = list(combo = wrap("box_no_facet", alpha=0.5), continuous = wrap("cor", size=4, alignPercent=0.8))) + theme(panel.grid.major = element_blank())
# Correlation matrix
corr_datos <- round(cor(datos[,2:10]), 2)
print(corr_datos)
library(corrplot)
# Asociaciones entre variables ACA VEMOS COLINEALIDAD
corrplot(corr_datos,
type = "upper",
method = "number")
# ejemplo:
# var original (x)
range(datos$POLIC) # [1]  0.000 11.263
# aplica raiz (x)
datos$SQ.POLIC <- sqrt(datos$POLIC)
# raiz de la var original (x)
range(datos$SQ.POLIC) # [1] 0.000000 3.356039
# aplica raiz al resto:
datos$SQ.SHRUB <- sqrt(datos$SHRUB)
datos$SQ.WAT.RES <- sqrt(datos$WAT.RES)
datos$SQ.L.P.ROAD <- sqrt(datos$L.P.ROAD)
datos$SQ.D.WAT.COUR <- sqrt(datos$D.WAT.COUR)
#### Ajuste el modelo (aditivo con todas las predictoras incluidas) en R y evalúe los supuestos
m1 <- glm(TOT.N ~ OPEN.L + MONT.S + SQ.POLIC +D.PARK + SQ.SHRUB + SQ.WAT.RES +
L.WAT.C +SQ.L.P.ROAD + SQ.D.WAT.COUR, family = poisson,data = datos)
#### analizar colinealidad
library(car)
vif(m1) # No hay problemas de vif
range(vif(m1))
# Parametro de dispersion (del modelo aditivo completo).   Se podria hacer backward o forward
(dispersion<-sum(resid(m1, type="pearson")^2/m1$df.residual))
# podemos usar performance para Prueba hip sobredispersion
library(performance)
check_overdispersion(m1) # Overdispersion detected
# Con paquete Dharma
#Simulaciones Dharma
library(DHARMa)
sim <- simulateResiduals(m1, n = 1000)
# Graficos diagnosticos
plot(sim)
hist(sim)
# prueba de dispersion
testDispersion(sim, plot=F) # tests if the simulated dispersion is equal to the observed dispersion
####
library(glmmTMB)
# Se comienza ajustando un modelo nulo (sin variables predictoras)
mnulo <- glmmTMB(TOT.N ~ 1, data = datos, family = nbinom2)
summary(mnulo) # sin predictoras
# evaluar la incorporacion de nuevas variables sobre "mnulo"
add1(mnulo, TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + D.PARK + SQ.SHRUB + SQ.WAT.RES + L.WAT.C +
SQ.L.P.ROAD + SQ.D.WAT.COUR, test="Chisq")
# Ajustar m2 incorporando al mnulo la variable seleccionada:
m2<-update(mnulo,.~.+D.PARK)
# evaluar la incorporacion de nuevas variables sobre m2
add1(m2, TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + D.PARK + SQ.SHRUB + SQ.WAT.RES + L.WAT.C +
SQ.L.P.ROAD + SQ.D.WAT.COUR, test="Chisq")
# Ajustar m3 incorporando al m2 la variable seleccionada:
m3<-update(m2,.~.+OPEN.L)
# evaluar la incorporacion de nuevas variables sobre m3
add1(m3, TOT.N ~ OPEN.L + MONT.S + SQ.POLIC + D.PARK + SQ.SHRUB + SQ.WAT.RES + L.WAT.C +
SQ.L.P.ROAD + SQ.D.WAT.COUR, test="Chisq")
# Ajustar m4 incorporando al m3 la variable seleccionada:
m4<-update(m3,.~.+L.WAT.C)
# evaluar la incorporacion de nuevas variables sobre m4
add1(m4, TOT.N ~ OPEN.L + MONT.S + SQ.POLIC +
D.PARK + SQ.SHRUB + SQ.WAT.RES + L.WAT.C +
SQ.L.P.ROAD + SQ.D.WAT.COUR, test="Chisq")
# Evaluar los supuestos del modelo seleccionado.
# Primero vemos si hay sobre o subdispersion
# Para m4
sum(resid(m4, type="pearson")^2)/(df.residual(m4)) # da re cercano a 1
simNB <- simulateResiduals(m4, n = 1000)
plot(simNB)
simNB <- simulateResiduals(m4, n = 10000)
plot(simNB)
hist(simNB)
# prueba de dispersion DHARMa
testDispersion(simNB, plot=F)
# Dispersion con performance
check_overdispersion(m4)
summary(m4)
#intervalos de confianza escala PL
round(confint(m4),5)
#intervalos de confianza escala PL
round(confint(m4),5)
summary(m4) # Esta en escala logaritmica
# escala VR
round(exp(fixef(m4)$cond), 5)
#Intervalos de confianza escala de la VR
m<-round(exp(confint(m4)),5)
exp(-0.0107)
m
exp(-0.0107)
#intervalos de confianza escala PL
round(confint(m4),5)
# hacemos (estimado de OpenL - 1) * 100 para saber magnitud de efecto
(0.98934-1)*100
(0.98311-1)*100
(0.99562-1)*100
# DPARK
# Escala VR- agarro ambos intervalos 2.5 y 95 y le resto uno
m<-as.matrix(m[,1:2])
m
(m-1)*100
library(ggeffects)
# cuantos graficos realiza? como se interpretan?
ggpredict(m4)
names(ggpredict(m4))
m4
plot(ggpredict(m4), add.data = TRUE)[1]
plot(ggpredict(m4), add.data = TRUE)[2]
plot(ggpredict(m4), add.data = TRUE)[3]
plot(ggpredict(m4), add.data = TRUE)[1] # Distance to natural park. A mayor distancia,
plot(ggpredict(m4), add.data = TRUE)[2] # Open lands
plot(ggpredict(m4), add.data = TRUE)[3] # Lenght of water courses
#### Modelo poisson (ya vimos que no era correcto)
# Ajuste del modelo reducido
# m5: con family Poisson
m5 <- glmmTMB(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = poisson, data = datos)
#Vemos los supuestos
#Simulaciones Dharma
sim <- simulateResiduals(m5, n = 1000)
plot(sim)
# m6: con family Tweedie (family=tweedie)
m6 <- glmmTMB(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = tweedie, data = datos)
m7 <- glmmTMB(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = compois, data = datos)
m7 <- glmmTMB(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = "quasipoisson", data = datos)
m7 <- glm(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = "quasipoisson", data = datos)
#Vemos los supuestos
#Simulaciones Dharma
sim6 <- simulateResiduals(m6, n = 1000)
plot(sim6) # Da horrible
m7 <- glmmTMB(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = compois, data = datos)
#Vemos los supuestos
#Simulaciones Dharma
sim7 <- simulateResiduals(m7, n = 1000)
plot(sim7) # Da horrible
m7 <- glmmTMB(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = compois, data = datos)
m7
summary(m7)
#Vemos los supuestos
#Simulaciones Dharma
sim8 <- simulateResiduals(m8, n = 1000)
m8 <- glm(TOT.N ~ OPEN.L +D.PARK + L.WAT.C, family = "quasipoisson", data = datos)
#Vemos los supuestos
#Simulaciones Dharma
sim8 <- simulateResiduals(m8, n = 1000)
plot(sim) # Da horrible
ggpredict(m6)
plot(ggpredict(m6), add.data = TRUE)[1] # Distance to natural park. A mayor distancia, menor muertos
plot(ggpredict(m6), add.data = TRUE)[2] # Open lands, mayor area descubierta menor muertos
plot(ggpredict(m6), add.data = TRUE)[3] # Lenght of water courses, mas largos mas muertos
ggpredict(m7)
plot(ggpredict(m7), add.data = TRUE)[1] # Distance to natural park. A mayor distancia, menor muertos
plot(ggpredict(m7), add.data = TRUE)[2] # Open lands, mayor area descubierta menor muertos
plot(ggpredict(m7), add.data = TRUE)[3] # Lenght of water courses, mas largos mas muertos
AIC(m4,m6,m7)
