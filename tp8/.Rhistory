axis.text.x = element_text(size = 10),
legend.title = element_text(size = 10),       # Tamaño del título de la leyenda
legend.text = element_text(size = 10)         # Tamaño del texto de la leyenda
)
ggplot(data, aes(x = factor(Acercamiento, levels = c(0, 1), labels = c("No", "Sí")), fill = factor(Acercamiento))) +
geom_bar(color = "lightgray") +
labs(x = "Acercamiento", y = "Frecuencia absoluta", title = "Distribución de acercamientos para machos y hembras") +
facet_grid(~Sexo,labeller=as_labeller(c("M" = "Machos (N=6)", "H" = "Hembras (N=9)"))) +
theme(legend.position = "none", axis.title.x = element_text(size = 14),
axis.title.y = element_text(size = 14),
axis.text.x = element_text(size = 10))
ggplot(data, aes(x = factor(Acercamiento, levels = c(0, 1), labels = c("No", "Sí")), fill = factor(Acercamiento))) +
geom_bar(color = "lightgray") +
labs(x = "Acercamiento", y = "Frecuencia absoluta", title = "Distribución de acercamientos para machos y hembras") +
facet_grid(~Sexo,labeller=as_labeller(c("M" = "Machos (N=6)", "H" = "Hembras (N=9)")), size=10) +
theme(legend.position = "none", axis.title.x = element_text(size = 14),
axis.title.y = element_text(size = 14),
axis.text.x = element_text(size = 10))
ggplot(data, aes(x = factor(Acercamiento, levels = c(0, 1), labels = c("No", "Sí")), fill = factor(Acercamiento))) +
geom_bar(color = "lightgray") +
labs(x = "Acercamiento", y = "Frecuencia absoluta", title = "Distribución de acercamientos para machos y hembras") +
facet_grid(~Sexo,labeller=as_labeller(c("M" = "Machos (N=6)", "H" = "Hembras (N=9)"))) +
theme(legend.position = "none", axis.title.x = element_text(size = 14),
axis.title.y = element_text(size = 14),
axis.text.x = element_text(size = 10),
strip.text = element_text(size = 16))
ggplot(data, aes(x = factor(Acercamiento, levels = c(0, 1), labels = c("No", "Sí")), fill = factor(Acercamiento))) +
geom_bar(color = "lightgray") +
labs(x = "Acercamiento", y = "Frecuencia absoluta", title = "Distribución de acercamientos para machos y hembras") +
facet_grid(~Sexo,labeller=as_labeller(c("M" = "Machos (N=6)", "H" = "Hembras (N=9)"))) +
theme(legend.position = "none", axis.title.x = element_text(size = 14),
axis.title.y = element_text(size = 14),
axis.text.x = element_text(size = 10),
strip.text = element_text(size = 10))
shapiro.test(alfai) #0.672
alfai<-ranef(m4)$ID$'(Intercept)'
#shapiro.test(alfai)
#qqPlot(alfai, main="QQ Plot residuos")
alfai<-ranef(m4)$ID$'(Intercept)'
shapiro.test(alfai)
alfai<-ranef(m4)
alfai$cond
alfai$zi
alfai<-ranef(m4)$cond
shapiro.test(alfai)
View(alfai)
alfai<-ranef(m4)$ID$'(Intercept)'
shapiro.test(alfai)
alfai<-ranef(m4)$ID$'(Intercept)'
alfai
alfai<-ranef(m4)$ID
alfai
alfai<-ranef(m4)
View(alfai)
alfai<-ranef(m4)$cond
View(alfai)
alfai<-ranef(m4)$cond$ID
alfai<-ranef(m4)$cond$ID$'(Intercept)'
alfai<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(alfai)
qqPlot(alfai, main="QQ Plot residuos")
library(car)
alfai<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(alfai)
qqPlot(alfai, main="QQ Plot residuos")
alfai<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(alfai)
#qqPlot(alfai, main="QQ Plot residuos")
alfai<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(alfai)
qqPlot(alfai, main="QQ Plot residuos")
# Modelo sin duración y sin descansos
# Sacamos los descansos dado que no encontramos efectos signifciativos x el tratamiento y no son parte de la pregunta de investigación.
m4 <- glmmTMB(Acercamiento ~ Tratamiento * Sexo + Sesión + (1|ID),
family = binomial,
data = data)
residuos<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(residuos)
qqPlot(residuos, main="QQ Plot residuos")
residuos<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(residuos)
qqPlot(residuos, main="QQ Plot residuos", xlab="Cuantiles normales")
residuos<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(residuos)
qqPlot(residuos, main="QQ Plot residuos", xlab="Cuantiles")
residuos<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(residuos)
qqPlot(residuos, main="QQ Plot residuos", xlab="Cuantiles teóricos")
Residuos<-ranef(m4)$cond$ID$'(Intercept)'
shapiro.test(Residuos)
qqPlot(Residuos, main="QQ Plot residuos", xlab="Cuantiles teóricos")
knitr::opts_chunk$set(echo = TRUE)
proporciones_ind <- data %>%
group_by(ID, Tratamiento) %>%
summarise(proporcion_acercamiento = mean(Acercamiento), .groups = 'drop')
library(dplyr)
library(ggplot2)
library(ggeffects)
library(glmmTMB)
library(DHARMa)
library(sjPlot)
library(performance)
library(car)
library(geepack)
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),contrast = list(infer = c(TRUE, TRUE))))
setwd("C:/Users/snpre/Documents/Carrera/Biometria II")
data<-read.csv("momias.csv", dec=",",stringsAsFactors=TRUE)
# Saco descansos, reordeno tratamientos
data <- droplevels(subset(data, Orden != 2 & Orden != 4))
data$Tratamiento<-factor(data$Tratamiento, levels=c("Juvenil heteroespecífico",  "Adulto conespecífico", "Juvenil conespecífico"))
# Convierto el ID en un factor con 12 niveles
data$ID<-as.factor(data$ID)
# Mismo con sesion
data$Sesión<-as.factor(data$Sesión)
str(data)
setwd("C:/Users/snpre/Documents/Carrera/Biometria II")
data<-read.csv("momias.csv", dec=",",stringsAsFactors=TRUE)
# Saco descansos, reordeno tratamientos
data <- droplevels(subset(data, Orden != 2 & Orden != 4))
data$Tratamiento<-factor(data$Tratamiento, levels=c("Juvenil heteroespecífico",  "Adulto conespecífico", "Juvenil conespecífico"))
# Convierto el ID en un factor con 12 niveles
data$ID<-as.factor(data$ID)
# Mismo con sesion
data$Sesión<-as.factor(data$Sesión)
str(data)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(ggeffects)
library(glmmTMB)
library(DHARMa)
library(sjPlot)
library(performance)
library(car)
library(geepack)
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),contrast = list(infer = c(TRUE, TRUE))))
setwd("C:/Users/snpre/Documents/Carrera/Biometria II")
data<-read.csv("momias.csv", dec=",",stringsAsFactors=TRUE)
# Saco descansos, reordeno tratamientos
data <- droplevels(subset(data, Orden != 2 & Orden != 4))
data$Tratamiento<-factor(data$Tratamiento, levels=c("Juvenil heteroespecífico",  "Adulto conespecífico", "Juvenil conespecífico"))
# Convierto el ID en un factor con 12 niveles
data$ID<-as.factor(data$ID)
# Mismo con sesion
data$Sesión<-as.factor(data$Sesión)
str(data)
setwd("C:/Users/snpre/Documents/Carrera/Biometria II")
data<-read.csv("momias.csv", dec=",",stringsAsFactors=TRUE)
# Saco descansos, reordeno tratamientos
data <- droplevels(subset(data, Orden != 2 & Orden != 4))
data$Tratamiento<-factor(data$Tratamiento, levels=c("Juvenil heteroespecífico",  "Adulto conespecífico", "Juvenil conespecífico"))
# Convierto el ID en un factor con 12 niveles
data$ID<-as.factor(data$ID)
# Mismo con sesion
#data$Sesión<-as.factor(data$Sesión)
str(data)
# Mismo con sesion
data$Sesión<-as.factor(data$Sesión)
setwd("C:/Users/snpre/Documents/Carrera/Biometria II")
data<-read.csv("momias.csv", dec=",",stringsAsFactors=TRUE)
setwd("C:/Users/snpre/Documents/Carrera/Biometria II")
data<-read.csv("momias.csv", dec=",",stringsAsFactors=TRUE)
# Saco descansos, reordeno tratamientos
data <- droplevels(subset(data, Orden != 2 & Orden != 4))
data$Tratamiento<-factor(data$Tratamiento, levels=c("Juvenil heteroespecífico",  "Adulto conespecífico", "Juvenil conespecífico"))
# Convierto el ID en un factor con 12 niveles
data$ID<-as.factor(data$ID)
# Mismo con sesion
data$Sesión<-as.factor(data$Sesión)
str(data)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(ggeffects)
library(glmmTMB)
library(DHARMa)
library(sjPlot)
library(performance)
library(car)
library(geepack)
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),contrast = list(infer = c(TRUE, TRUE))))
setwd("C:/Users/snpre/Documents/Carrera/Biometria II")
data<-read.csv("momias.csv", dec=",",stringsAsFactors=TRUE)
# Saco descansos, reordeno tratamientos
data <- droplevels(subset(data, Orden != 2 & Orden != 4))
data$Tratamiento<-factor(data$Tratamiento, levels=c("Juvenil heteroespecífico",  "Adulto conespecífico", "Juvenil conespecífico"))
# Convierto el ID en un factor con 12 niveles
data$ID<-as.factor(data$ID)
# Mismo con sesion
data$Sesión<-as.factor(data$Sesión)
str(data)
m_simcomp <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "exchangeable")
m_ar1 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "ar1")
m_desest <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "unstructured")
QIC(m_simcomp, m_ar1, m_desest)
m_simcomp <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión,
id = ID,
family = binomial,
data = data,
corstr = "exchangeable")
m_ar1 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "ar1")
m_desest <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "unstructured")
QIC(m_simcomp, m_ar1, m_desest)
m_simcomp <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "exchangeable")
m_ar1 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "ar1")
m_desest <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión + Duración,
id = ID,
family = binomial,
data = data,
corstr = "unstructured")
QIC(m_simcomp, m_ar1, m_desest)
# Esto también sucede sin incluir a la covariable Duración
m_simcomp2 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión,
id = ID,
family = binomial,
data = data,
corstr = "exchangeable")
m_ar1_2 <- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión,
id = ID,
family = binomial,
data = data,
corstr = "ar1")
m_desest2<- geeglm(Acercamiento ~ Tratamiento * Sexo + Sesión,
id = ID,
family = binomial,
data = data,
corstr = "unstructured")
QIC(m_simcomp2, m_ar1_2, m_desest2)
setwd("C:/Users/snpre/Documents/Carrera/Biometria II/tp8")
## Carga del data.frame
Datos<- read.delim("tyto.txt", stringsAsFactors = T)
## Carga del data.frame
Datos<- read.delim("tyto.txt", stringsAsFactors = T)
str(Datos)
##########################
#####   Problema 4   #####
##########################
library(glmmTMB)
Datos$prop_aves <- Datos$N_aves/Datos$N_presas
# Chequear que se haya creado correctamente la nueva variable
class(Datos$prop_aves)   # numeric
Datos$prop_aves
summary(Datos$prop_aves)
# Este enfoque incorpora al ultimo nivel de observacion como factor aleatorio. Por lo tanto, ahora se trata d eun modelo mixto
modelo1OLRE <- glmmTMB(prop_aves ~ Region*porc_urbano + (1|ID),family = binomial,weights = N_presas,data = Datos)
drop1(modelo1OLRE, test = "Chisq")
modelo2OLRE <- glmmTMB(prop_aves ~ Region+porc_urbano + (1|ID),family = binomial,weights = N_presas,data = Datos)
drop1(modelo2OLRE, test = "Chisq")
modelo3OLRE <- glmmTMB(prop_aves ~ Region+porc_urbano + (1|ID),family = binomial,weights = N_presas,data = Datos)
drop1(modelo3OLRE, test = "Chisq")
modelo3OLRE <- glmmTMB(prop_aves ~ Region+ (1|ID),family = binomial,weights = N_presas,data = Datos)
drop1(modelo3OLRE, test = "Chisq")
# Supuestos
sum(resid(modelo3ORLE, type="pearson")^2)/modelo3ORLE$df.residual
# Modelo simple, sin porc urbano
modelo3OLRE <- glmmTMB(prop_aves ~ Region+ (1|ID),family = binomial,weights = N_presas,data = Datos)
# Supuestos
sum(resid(modelo3ORLE, type="pearson")^2)/modelo3ORLE$df.residual
# Supuestos
sum(resid(modelo3OLRE, type="pearson")^2)/modelo3OLRE$df.residual
library(DHARMa)
testDispersion(M1, type = "DHARMa")  # la funcion testDispersion permite setear el calculo del F dispersion (tipo DHARMa o Tipo Pearson -este ultimo es equivalente a sum(resid(M1, type="pearson")^2)/M1$df.residual)
testDispersion(modelo3OLRE, type = "DHARMa")  # la funcion testDispersion permite setear el calculo del F dispersion (tipo DHARMa o Tipo Pearson -este ultimo es equivalente a sum(resid(M1, type="pearson")^2)/M1$df.residual)
testDispersion(M1, type = "PearsonChisq")
testDispersion(modelo3OLRE, type = "PearsonChisq")
# Gráficos de res reescalados
sim <- simulateResiduals(fittedMod = M1, modelo3OLRE = T)
# Gráficos de res reescalados
sim <- simulateResiduals(fittedMod = modelo3OLRE, plot = T)
### ***1)*** quasibinomial
##############################
# Modelo simple solo con Region
Mquasi <- glm(prop_aves ~ Region,family = quasibinomial, weights = N_presas, data = Datos)
drop1(M3q, test = "F")
mBetaBin <-glmmTMB(prop_aves ~  Region, family=betabinomial, weights=N_presas, data=Datos)
AIC(modelo3OLRE, mBetaBin, Mquasi)
ist=ls(
(
# Si te aparece character(0) es que la memoria esta limpia, si no ejecuta
# la siguiente sentencia para borrar la memoria:
rm(list=ls())
library(ggplot2)     # La vamos a utilizar para graficas
library(dplyr)       # La vamos a utilizar para armar tablas resumen
library(car)         # La vamos a utilizar para analisis de algunos supuestos
library(glmmTMB)     # La vamos a utilizar para ajustar el modelo
library(DHARMa)      # La vamos a utilizar para analizar supuestos
library(performance) # La vamos a utilizar para analizar supuestos y más ...
library(emmeans)     # La vamos a utilizar para realizar comparaciones
library(ggeffects)   # La vamos a utilizar para obtener (y graficar) los valores predichos por el modelo
library(sjPlot)      # Alternativa para ggeffcets y grafico de efectos aleatorios
# setwd("ruta de acceso")
setwd("~/Documents/Carrera/Biometria II/tp8")
# setwd("ruta de acceso")
setwd("C:/snpre/Documents/Carrera/Biometria II/tp8")
setwd("~/Carrera/Biometria II/tp8")
# setwd("ruta de acceso")
setwd("~/Carrera/Biometria II/tp8")
Datos  <- read.csv("aves.csv", stringsAsFactors = T)
class(Datos)     # tipo de objeto Datos
str(Datos)       # estructura
dim(Datos)       # dimensiones
head(Datos)      # primeras 6 filas (se pueden pedir mas filas si lo desean)
summary(Datos)   # resuemn de las variables
Datos$Parcela <- as.factor(Datos$Parcela) #¿por qué pasamos únicamente a parcela como factor?
# Agrupando las parcelas
descAgrupParcelas <- Datos %>%
group_by(Zona, Uso) %>%
summarise_at("Abundancia", c(
n = length,
media_aves = mean,
sd_aves = sd))
# Discriminado por parcela
descPorParcela <- Datos %>%
group_by(Zona, Uso, Parcela) %>%
summarise_at("Abundancia", c(
n = length,
media_aves = mean,
sd_aves = sd))  %>%
arrange(Parcela)
descPorParcela
descAgrupParcelas
# Discriminado por parcela
descPorParcela <- Datos %>%
group_by(Zona, Uso, Parcela) %>%
summarise_at("Abundancia", c(
n = length,
media_aves = mean,
sd_aves = sd))  %>%
arrange(Parcela)
descPorParcela
View(Datos)
# todas las observaciones ...
ggplot(data = Datos, aes(x = Zona, y = Abundancia, fill=Uso)) +
geom_boxplot() +
ylab("Abundancia aves nativas (n°/5 min)") +
geom_point(alpha=0.3, position=position_jitterdodge()) # dogde desplaza horizontalmente los puntos, asi evitamos solapamiento y ayuda a la visualización
## Gráficos
library(ggplot2)
library(ggplot2)     # La vamos a utilizar para graficas
library(dplyr)       # La vamos a utilizar para armar tablas resumen
library(car)         # La vamos a utilizar para analisis de algunos supuestos
library(glmmTMB)     # La vamos a utilizar para ajustar el modelo
library(DHARMa)      # La vamos a utilizar para analizar supuestos
library(performance) # La vamos a utilizar para analizar supuestos y más ...
library(emmeans)     # La vamos a utilizar para realizar comparaciones
library(ggeffects)   # La vamos a utilizar para obtener (y graficar) los valores predichos por el modelo
library(sjPlot)      # Alternativa para ggeffcets y grafico de efectos aleatorios
# todas las observaciones ...
ggplot(data = Datos, aes(x = Zona, y = Abundancia, fill=Uso)) +
geom_boxplot() +
ylab("Abundancia aves nativas (n°/5 min)") +
geom_point(alpha=0.3, position=position_jitterdodge()) # dogde desplaza horizontalmente los puntos, asi evitamos solapamiento y ayuda a la visualización
# con los promedios de las parcelas
ggplot(data = descPorParcela , aes(x = Uso, y = media_aves, fill=Zona)) +
geom_point(aes(colour=Parcela), alpha=0.5) + # se puede agregar el jitter
ylab("Abundancia aves nativas (n°/5 min)") +
facet_grid(. ~Zona)
Datos$Parcela <- as.factor(Datos$Parcela) #¿por qué pasamos únicamente a parcela como factor? Porque tecnicamente es cualitativa, la parcela 16 no es 16 veces la parcela 1
# con los promedios de las parcelas
ggplot(data = descPorParcela , aes(x = Uso, y = media_aves, fill=Zona)) +
geom_point(aes(colour=Parcela), alpha=0.5) + # se puede agregar el jitter
ylab("Abundancia aves nativas (n°/5 min)") +
facet_grid(. ~Zona)
View(Datos)
## modelando la abundancia con GLMM
m1 <- glmmTMB(Abundancia ~  Uso*Zona + (1|Parcela),
data =Datos, family = poisson)
# parametro de dispersion
e1 <- resid(m1, type = "pearson")
dispersion <- sum(e1^2) / df.residual(m1)
dispersion
# analisis supuestos con Dharma
simm1 <- simulateResiduals(fittedMod = m1) # , refit = T
plot(simm1)
plotResiduals(simm1, Datos$Uso)
plotResiduals(simm1, Datos$Zona)
testDispersion(simm1)
alfai <- ranef(m1)
### QQ plot
car::qqPlot(alfai$cond$Parcela$`(Intercept)`)
### prueba de shapiro
shapiro.test(alfai$cond$Parcela$`(Intercept)`)
m2_cmp <- glmmTMB(Abundancia ~  Uso*Zona + (1|Parcela), data = Datos, family=compois)
# parametro de dispersion
e1 <- resid(m2_cmp, type = "pearson")
dispersion <- sum(e1^2) / df.residual(m2_cmp)
dispersion
# analisis supuestos con Dharma
simCMP <- simulateResiduals(fittedMod = m2_cmp) # , refit = T
plot(simCMP)
testDispersion(simCMP)
# dispersion = 1.0987, p-value = 0.432
plotResiduals(simCMP, Datos$Uso)
plotResiduals(simCMP, Datos$Zona)
alfai <- ranef(m2_cmp)
### QQ plot
car::qqPlot(alfai$cond$Parcela$`(Intercept)`)
shapiro.test(alfai$cond$Parcela$`(Intercept)`)
alfai <- ranef(m2_cmp)
### QQ plot
car::qqPlot(alfai$cond$Parcela$`(Intercept)`)
shapiro.test(alfai$cond$Parcela$`(Intercept)`)
#W = 0.93053, p-value = 0.2486
# alternativa grafica
library(sjPlot)
plot_model(m2_cmp, type = "diag")
### prueba de shapiro
shapiro.test(alfai$cond$Parcela$`(Intercept)`)
# termino de interaccion:
drop1(m2_cmp,test="Chi")
summary(m2_cmp)
# efectos aleatorios
(alfai<-ranef(m2_cmp)) # escala PL
exp(alfai$cond$Parcela) # escala VR
emm_options(emmeans = list(infer = c(TRUE, FALSE)),
contrast = list(infer = c(TRUE, TRUE)))
# Escala del Predictor lineal
efsimpleZona<- emmeans(m2_cmp, pairwise ~ Uso | Zona) #Tukey por default
plot(efsimpleZona$emmeans, comparisons = TRUE)
efsimpleZona
# Escala de la variable respuesta
efsimpleZona<- emmeans(m2_cmp, pairwise ~ Uso | Zona, type="response") #Tukey por default
plot(efsimpleZona$emmeans, comparisons = TRUE)
efsimpleZona
## modelo final resumen (tabla y grafico predictivo)
# con ggeffects
library(ggeffects)
a <- ggpredict(m2_cmp, terms= c("Zona","Uso"))
a
plot(a, add.data=F, grid = F )
# Grafico escala exponencial
plot_model(m2_cmp,
type="re",
vline.color = "grey4",
show.values = TRUE,
sort.est = F,
grid = F,
value.offset = .3,
title = "ranef (exponencial)")
alfai <- ranef(m2_cmp)
exp(alfai$cond$Parcela$`(Intercept)`) # escala exp
sort(exp(alfai$cond$Parcela$`(Intercept)`))
# Grafico escala exponencial
plot_model(m2_cmp,
type="re",
vline.color = "grey4",
show.values = TRUE,
sort.est = F,
grid = F,
value.offset = .3,
title = "ranef (exponencial)")
# estimados e IC
get_model_data(m2_cmp, type = "re")
# escala del PL
plot_model(m2_cmp,
type="re",
vline.color = "grey4",
show.values = TRUE,
sort.est = T,
grid = F,
value.offset = .3,
transform = NULL,
title = "ranef")
alfai <- ranef(m2_cmp)
alfai$cond$Parcela$`(Intercept)`
rm(list=ls())
library(ggplot2)     # La vamos a utilizar para graficas
library(dplyr)       # La vamos a utilizar para armar tablas resumen
library(car)         # La vamos a utilizar para analisis de algunos supuestos
library(glmmTMB)     # La vamos a utilizar para ajustar el modelo
library(DHARMa)      # La vamos a utilizar para analizar supuestos
library(performance) # La vamos a utilizar para analizar supuestos y más ...
library(emmeans)     # La vamos a utilizar para realizar comparaciones
library(ggeffects)   # La vamos a utilizar para obtener (y graficar) los valores predichos por el modelo
library(sjPlot)      # Alternativa para ggeffcets y grafico de efectos aleatorios
setwd("~/Carrera/Biometria II/tp8")
datos <- read.delim("Rcomensales.txt", stringsAsFactors = T)
str(datos)
summary(datos)
head(datos)
head(datos, 10)
