contrast = list(infer = c(TRUE, TRUE)))) # opciones de seteo de las opciones de salida
# Escala del predictor lineal - Logaritmica
compPL <- emmeans(m3, pairwise ~ Tratamiento) # Tukey por default
View(datos)
# Escala del predictor lineal - Logaritmica
compPL <- emmeans(m3, pairwise ~ trat) # Tukey por default
compPL
# Escala de la variable respuesta
compVR <- emmeans(m3, pairwise ~ trat, type="response") # Tukey por default
compVR
plot(compVR)
plot(compVR, comparisons = TRUE)
# Con la libreria SJPlot
plot_model(m3, type = "pred", terms = c("trat"))+ geom_jitter(data=datos, aes(x=as.numeric(trat),y=n_huevos), width=0.2)
# Con ggeffects
model_plot <- ggpredict(m3,
terms = c("trat[control, glifo_alta, glifo_baja]"),
interval = "confidence")
model_plot
plot(model_plot, add.data = T, jitter = 0.3, color="blue")   +
xlab("Dosis de glifosato") +
ylab("Numero de huevos por hembra")
plot(model_plot, add.data = T, jitter = 0.3, color="blue")   +
xlab("Dosis de glifosato") +
ylab("Numero de huevos por hembra")
compVR
m
(m-1)*100
# Si te aparece character(0) es que la memoria esta limpia, si no ejecuta
# la siguiente sentencia para borrar la memoria.
rm(list=ls())
### Setear directorio de trabajo
setwd("~/Documents/Carrera/Biometria II/tp7")
### Setear directorio de trabajo
setwd("C:/Users/snpre/Documents/Carrera/Biometria II/tp7")
# librerias necesarias:
library(dplyr)             # manipulacion de data.frames (descriptiva)
library(ggplot2)           # graficos
library(gridExtra)         # para plotear multiples graficos
library(ResourceSelection) # para evaluar bondad de ajuste
library(car)               # para funcion Anova (sino drop1)
library(emmeans)           # comparaciones
library(ggeffects)         # predichos del modelo
library(DHARMa)            # analisis supuestos
datospalmar <- read.delim("~/Documents/Docencia/Biome2_2024/TP7/DatosPalmar1.txt", stringsAsFactors = T)
datospalmar <- read.delim("~/Documents/Docencia/Biome2_2024/TP7/DatosPalmar1.txt", stringsAsFactors = T)
datospalmar <- read.delim("DatosPalmar1.txt", stringsAsFactors = T)
# Exploracion del data.frame: estructura, clases, niveles, datos faltantes, etc.
str(datospalmar)
#'data.frame':	100 obs. of  3 variables:
#$ exclusion    : Factor w/ 2 levels "jaula","sinjaula": 2 2 2 2 2 2 2 2 2 2 ...
#$ distancia    : int  388 222 55 199 84 114 318 489 190 278 ...
#$ supervivencia: int  1 1 1 1 1 0 1 0 0 1 ...
head(datospalmar)
tail(datospalmar)
dim(datospalmar)
# View(datospalmar) para visualizar en otra pestania
summary(datospalmar)
# supervivencia segun condicion de exclusion
datospalmar %>%
select(exclusion, supervivencia) %>%
group_by(exclusion) %>%
summarise_all(.funs = c(
n = length,
media = mean,
sd = sd,
min = min,
max = max
)
)
# distancia segun condicion de exclusion
datospalmar %>%
select(exclusion, distancia) %>%
group_by(exclusion) %>%
summarise_all(.funs = c(
n = length,
media = mean,
sd = sd,
min = min,
max = max
)
)
# De que tipo es la variable respuesta? dicotomica
# Que valores puede tomar? exito fracaso, plantula viva o muerta, 1 o 0
# Como es potencial distribucion de probabilidades? ~ Bernoulli (pi_i) o Binomial (pi_i, 1)
class(datospalmar$supervivencia)
summary(datospalmar$supervivencia)
datospalmar$supervivencia
supVsExc <- ggplot(datospalmar, aes(x = exclusion, y = supervivencia)) +
geom_jitter(height = 0.01, width = 0.1) +
theme(axis.text.x=element_text(size=15))
supVsExc
#  supervivencia vs distancia:
supVsDist <-  ggplot(datospalmar, aes(x=distancia, y= supervivencia)) +
geom_jitter(height = 0.01, width = 0.1) +
xlab("dist a la palmera adulta (cm)") +
ylab("") +
theme(axis.text.x=element_text(size=15))
supVsDist
supVsDistExc <- ggplot(datospalmar, aes(x=distancia, y= supervivencia,colour = exclusion)) +
geom_jitter(height = 0.01, width = 0.1) +
# geom_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE)  +  # para agregar un suavizado glm binomial
xlab("dist a la palmera adulta (cm)") +
ylab("") +
theme(axis.text.x=element_text(size=15))
supVsDistExc
library(gridExtra)
grid.arrange(supVsExc, supVsDist, supVsDistExc, ncol=3, nrow=1)
# Cuantas plantulas sobrevivieron del total?
table(datospalmar$supervivencia, useNA = "always")
# Cuantas plantulas protegidas de los jabalies (jaula) sobrevivieron y,cuantas de las que no tenian  proteccion?
table(datospalmar$exclusion, datospalmar$supervivencia)
(35/50)*100
(23/50)*100 #
# Estimacion de la pb sobrevivir dado que estan protegidas
35/(15+35)
# Estimacion de la pb de NO sobrevivir dado que estan protegidas
15/(15+35)
#### con juala (protegidas)
odd_protegidas <-  0.7 / 0.3
odd_protegidas
#### Para hacer:
#### sin jaula (NO protegidas)
odd_NO_protegidas <-  0.46/0.54
odd_NO_protegidas
# Paso el nivel SIN jaula a la intercept (ayudara a la interpretacion de los resultados)
levels(datospalmar$exclusion)
datospalmar$exclusion <- factor(datospalmar$exclusion,
levels = c("sinjaula", "jaula"))
levels(datospalmar$exclusion)
# con glm
m_con_int <- glm(supervivencia ~  exclusion*distancia,
data =datospalmar, family = binomial)
# otra opcion: glmmTMB
library(glmmTMB)
m1 <-  glmmTMB(supervivencia ~  exclusion*distancia,
data =datospalmar, family = binomial)
library(DHARMa)
sim <- simulateResiduals(fittedModel = m_con_int, plot = T)
plot(sim)
testDispersion(sim)
plot(sim)
# Que puede concluir acerca de la interaccion distancia * condicion de exclusion
# Concluya
library(car)
Anova(m_con_int)
# alternativamente drop1
drop1(m_con_int, test="Chisq")
# vemos el summary
summary(m_con_int)
# Modelo sin interaccion:
m_aditivo <- glm(supervivencia ~  exclusion + distancia,
data =datospalmar, family = binomial)
summary(m_aditivo)
drop1(m_aditivo , test="Chisq")
# Analisis supuestos:
sim <- simulateResiduals(fittedModel = m_aditivo, plot = T)
# por variable
plotResiduals(sim, datospalmar$exclusion) #### notar que devuelve un grafico de cajas
plotResiduals(sim, datospalmar$distancia)
# Analisis supuestos:
sim <- simulateResiduals(fittedModel = m_aditivo, plot = T)
# Analisis supuestos:
sim <- simulateResiduals(fittedModel = m_aditivo, plot = T, n=10000)
# por variable
plotResiduals(sim, datospalmar$exclusion) #### notar que devuelve un grafico de cajas
plotResiduals(sim, datospalmar$distancia)
# del summary
summary(m_aditivo)
# fc coef
coef(m_aditivo)
-1.1574+1.1206
# escala de ODDS
exp(coef(m_aditivo))
(1.0040265-1)*100
#### Comparaciones
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),contrast = list(infer = c(TRUE, TRUE))))
#en escala del PL
comp <- emmeans(m_aditivo, pairwise ~ exclusion, adjust = "tukey") #Tukey por default
summary(comp)
plot(comp, comparisons = TRUE)
#en escala de la VR
compVR <- emmeans(m_aditivo, pairwise ~ exclusion, type = "response") #Tukey por default
summary(compVR)
plot(compVR, comparisons = TRUE)
# explorar el objeto ref_grid (para saber que valor de distancia usa)
ref_grid(m_aditivo)
# distancia que toma
mean(datospalmar$distancia)
#### Algunas conclusiones y resultados
summary(m_aditivo)
exp(confint(m_aditivo))
compVR
#### Cuentas? #### Salen a partir del los imites del IC para diferencia de medias en escala de la VR (sinjaula / jaula)
# p / L inf
(0.138-1)*100
# p / L sup
(0.771-1)*100
summary(m_aditivo)
# Por otra parte, tanto frente a la exclusión o no de jabalíes, se observa que la supervivencia de las plántulas (disminuye/*aumenta*) con la distancia a la palmera más cercana, sugiriendo un posible mecanismo de competencia intraespecífica. Se estima que por cada cm que aumenta la distancia a la palmera más cercana la supervivencia aumenta en promedio entre ……   y ……  , independientemente de la presencia o no de jabalíes.
exp(confint(m_aditivo))
#### Cuentas? ####  salen de exp(confint(m_aditivo))
# p / L inf
(1.0007229-1)*100
# p / L sup
(1.0076344-1)*100
library(ggeffects)
predichos <-ggpredict(m_aditivo,
terms = ~distancia+exclusion,
interval = "confidence")
predichos
plot(ggpredict(m_aditivo, terms = ~distancia+exclusion))+
labs(y="Supervivencia de la plantula de B. yatay") +
labs(x="Distancia a la palmera adulta mas cercana (cm)")
plot(ggpredict(m_aditivo, terms = ~distancia+exclusion))+
labs(y="Supervivencia de la plantula de B. yatay") +
labs(x="Distancia a la palmera adulta mas cercana (cm)")
#predichos en escala del predictor lineal
datospalmar$pl<-predict(m_aditivo, type="link")
#predichos en escala de la VR
datospalmar$pre<-predict(m_aditivo, type="response")
# Escala del predictor lineal
Graf_PL <- ggplot(datospalmar, aes(distancia, pl, group=exclusion, colour=exclusion)) +
labs(x="distancia (cm)", y="logit(p supervivencia)") +
geom_smooth(method = lm,  se = FALSE) +
theme(axis.title=element_text(size=14)) +
theme(legend.position = "none")
# escala del odds
odd <- exp(datospalmar$pl)
Graf_ODD <- ggplot(datospalmar, aes(distancia, odd, group=exclusion, colour=exclusion)) +
geom_point( size = 2) + labs(x="distancia (cm)", y="odds(supervivencia)")+
theme(axis.title=element_text(size=14)) +
geom_smooth(se = FALSE) +
theme(legend.position = "none")
# escala de probabilidades
Graf_proba <- ggplot(datospalmar, aes(distancia, pre, group=exclusion, colour=exclusion)) +
geom_point( size = 2) + labs(x="distancia (cm)", y="p(supervivencia)")+
theme(axis.title=element_text(size=14)) +
geom_smooth(method="glm", method.args=list(family=gaussian(link="logit")), se = FALSE) +
theme(legend.position = c(0.8, 0.3))
library(gridExtra)
grid.arrange(Graf_PL, Graf_ODD, Graf_proba, ncol=3, nrow=1)
# numerador
# con estos comandos extraigo los 3 coeficientes
# para no tener que redondearlos
coef(m_aditivo)[[1]]
coef(m_aditivo)[[2]]
coef(m_aditivo)[[3]]
num <- exp(coef(m_aditivo)[[1]] + coef(m_aditivo)[[2]] + coef(m_aditivo)[[3]]*200)
# denominador
den <- 1 + exp(coef(m_aditivo)[[1]] + coef(m_aditivo)[[2]] + coef(m_aditivo)[[3]]*200)
num/den # 0.6828475
compVR
exp(confint(m_aditivo))
# Hoslmen test buen ajuste regresion logistica
library(ResourceSelection)
hl <- hoslem.test(datospalmar$supervivencia, fitted(m_aditivo), g=10)
hl
# para ver graficamente lo que está haciendo el test.
pred <- m_aditivo$fitted.values # predicted values (100 valores predichos)
var <-as.numeric(datospalmar$supervivencia) # var= variable respuesta
N <-10 # number of intervalos  (g=10)
secu <- c(-0.00001,(1:N)/N) # puntos de corte
grupos <- cut(pred,secu) # agrupamos los pred en intervalos
valores<-unlist(lapply(split(var,grupos),mean)) # las medias de cada intervalo
cexs<-unlist(lapply(split(var,grupos),sum))
plot(secu[-1]-1/N/2,valores,pch=16,xlim=c(0,1),ylim=c(0,1),xlab='Pb predicha',ylab='Frec observada')
abline(0,1)
######################################
#### Evaluando capacidad predictiva
######################################
#curva ROC
library(Epi)
curvaROc <- ROC(form=supervivencia~exclusion+distancia, data=datospalmar)
curvaROc$AUC
hl
setwd("C:/Users/snpre/Documents/Carrera/Biometria II/tp7")
## Carga del data.frame
Datos<- read.delim("tyto.txt", stringsAsFactors = T)
str(Datos)
#### **************************
#### Exploracion del data.frame
#### **************************
str(Datos)
summary(Datos)
head(Datos)
Datos$prop_aves <- Datos$N_aves/Datos$N_presas
class(Datos$prop_aves)
Datos$prop_aves
summary(Datos$prop_aves)
# cantidad de NO aves en el total de presas
Datos$no_aves <- Datos$N_presas-Datos$N_aves
summary(Datos$no_aves)
library(dplyr)
library(ggplot2)
#Medidas resumen de prop_aves por region
Datos %>%
select(Region, prop_aves) %>%
group_by(Region) %>%
summarise_all(.funs = c(
n = length,
media = mean,
sd = sd,
min = min,
max = max
)) %>%
mutate_if(is.numeric, round, 3) #Este argumento es para setear cuantos dígitos luego de la coma
#Medidas resumen: "n" presas totales, presas aves y presas no_aves
Datos %>%
select(Region, N_presas, N_aves, no_aves) %>%
group_by(Region) %>%
summarise_all(.funs = c(
total = sum
)) %>%
mutate_if(is.numeric, round, 3) #Este argumento es para setear cuantos dígitos luego de la coma
# Medidas resumen porcentaje de urbanizacion por region
Datos %>%
select(Region, porc_urbano) %>%
group_by(Region) %>%
summarise_all(.funs = c(
n = length,
media = mean,
sd = sd,
min = min,
max = max
)) %>%
mutate_if(is.numeric, round, 3)
#Medidas resumen: "n" presas totales, presas aves y presas no_aves
Datos %>%
select(Region, N_presas, N_aves, no_aves) %>%
group_by(Region) %>%
summarise_all(.funs = c(
total = sum
)) %>%
mutate_if(is.numeric, round, 3) #Este argumento es para setear cuantos dígitos luego de la coma
#ODDS Delta
(294/4137)/(3843/4137)
#Medidas resumen: "n" presas totales, presas aves y presas no_aves
Datos %>%
select(Region, N_presas, N_aves, no_aves) %>%
group_by(Region) %>%
summarise_all(.funs = c(
total = sum
)) %>%
mutate_if(is.numeric, round, 3) #Este argumento es para setear cuantos dígitos luego de la coma
#Medidas resumen de prop_aves por region
Datos %>%
select(Region, prop_aves) %>%
group_by(Region) %>%
summarise_all(.funs = c(
n = length,
media = mean,
sd = sd,
min = min,
max = max
)) %>%
mutate_if(is.numeric, round, 3) #Este argumento es para setear cuantos dígitos luego de la coma
# por region
qplot(x=Region, y=prop_aves, data=Datos, geom=c("boxplot","jitter"), fill=Region)
# en funcion del porcentaje de urbano discriminado por region
ggplot(Datos, aes(x=porc_urbano, y=prop_aves, colour=Region, group=Region)) + geom_point(size=3)
## variable respuesta proporcion (se debe incluir el n total como "weights")
M1 <- glm(prop_aves ~ Region * porc_urbano, family = binomial, weights = N_presas, data = Datos)
## variable respuesta "exitos, fracasos")
M1b <- glm(cbind(N_aves, (N_presas-N_aves)) ~ Region * porc_urbano,family = binomial,data = Datos)
AIC(M1,M1b)
M1==M1b
car::vif(M2) ### con esta sintaxis se llama a la funcion vif del paquete car
# Se chequea con modelo aditivo (en el modelo con interaccion ?que pasaria?)
# En un modelo con interaccion habria colinealidad espuria
# lA INTERACCION FUERZA LA COLINDEALIDAD
# Esto es exactamente igual a los modelos de arriba, no se porque se hace de nuevo
M2 <- glm(prop_aves ~ Region + porc_urbano, family = binomial, weights = N_presas,data = Datos)
car::vif(M2) ### con esta sintaxis se llama a la funcion vif del paquete car
### Analisis de los SUPUESTOS
# A DIFERENCIA DE BERNOULLI, ACA SI CHEQUEAMOS DISPERSION YA NO HYA VR DICOTOMICA!
# F dispersion
sum(resid(M1, type="pearson")^2)/M1$df.residual
library(DHARMa)
testDispersion(M1, type = "DHARMa")  # la funcion testDispersion permite setear el calculo del F dispersion (tipo DHARMa o Tipo Pearson -este ultimo es equivalente a sum(resid(M1, type="pearson")^2)/M1$df.residual)
testDispersion(M1, type = "PearsonChisq") # ESTE DA IGUAL AL ORIGINAL, AL QUE HACEMOS A MANO
# Gráficos de res reescalados
sim <- simulateResiduals(fittedMod = M1, plot = T)
# RECHAZO TODO. Hay mayor dispersion, hay outliers, no hay distribucion uniforme
# Tambien rechaoz el test KS, no hay bondad de ajuste
plotResiduals(sim, Datos$Region)
plotResiduals(sim, Datos$porc_urbano)
# Modelo con interaccion
M1q <- glm(prop_aves ~ Region * porc_urbano,family = quasibinomial, weights = N_presas, data = Datos)
drop1(M1q, test = "F")
# Modelo aditivo
M2q <- glm(prop_aves ~ Region + porc_urbano, family = quasibinomial, weights = N_presas, data = Datos)
drop1(M2q, test = "F")
# Modelo simple solo con Region
M3q <- glm(prop_aves ~ Region,family = quasibinomial, weights = N_presas, data = Datos)
drop1(M3q, test = "F")
#% de Devianza explicada (pseudo R2)
(summary(M3q)$null.deviance-summary(M3q)$deviance)/summary(M3q)$null.deviance*100
library(emmeans)
options(emmeans= list(emmeans = list(infer = c(TRUE, FALSE)),contrast = list(infer = c(TRUE, TRUE))))
#en escala del PL
comp <- emmeans(M3q, pairwise ~ Region, adjust = "tukey") #Tukey por default
summary(comp)
plot(comp, comparisons = TRUE)
#en escala de la VR
compVR <- emmeans(M3q, pairwise ~ Region, type = "response") #Tukey por default
summary(compVR)
plot(compVR, comparisons = TRUE)
## modelo final resumen
library(ggeffects)
predichos <-ggpredict(M3q,
terms = ~ Region,
interval = "confidence")
predichos
plot(ggpredict(M3q, terms = ~Region))+
labs(y="Region") +
labs(x="prob consumo de aves")
# grafico de medias con IC95% en escala de pb
# opcion con emmeans
estad <-as.data.frame(compVR$emmeans)
estad
# grafico de medias con IC95% en escala de pb
# opcion con emmeans
estad <-as.data.frame(compVR$emmeans)
estad
# Las barras de error representan el DE
library(ggplot2)
ggplot(estad, aes(x=Region, y=prob)) +
geom_errorbar(aes(ymin=asymp.LCL, ymax=asymp.UCL), width=.1) +
geom_point(colour = "red", size = 3)+ ylab("prob consumo de aves") +
theme_grey(base_size = 16) +
annotate("text", x = c(1, 2, 3),
y = c(0.1, 0.04, 0.06),
label = c("B", "A", "A")) +
theme_bw()
modelo1BetaBin <-glmmTMB(prop_aves ~  Region*porc_urbano, family=betabinomial, weights=N_presas, data=Datos)
summary(modelo1BetaBin)
#### Modelo betabinomial
library("glmmTMB")
modelo1BetaBin <-glmmTMB(prop_aves ~  Region*porc_urbano, family=betabinomial, weights=N_presas, data=Datos)
summary(modelo1BetaBin)
# Solo region pampa da significativo
drop1(modelo1BetaBin, test = "Chisq")
modelo2BetaBin <-glmmTMB(prop_aves ~  Region+porc_urbano, family=betabinomial, weights=N_presas, data=Datos)
summary(modelo2BetaBin)
# Region pampa tambien da significativa
drop1(modelo2BetaBin, test = "Chisq")
modelo3BetaBin <-glmmTMB(prop_aves ~  Region, family=betabinomial, weights=N_presas, data=Datos)
summary(modelo3BetaBin)
drop1(modelo3BetaBin, test = "Chisq")
### Mas adelante (GLMM)
modelo1OLRE <- glmmTMB(prop_aves ~ Region*porc_urbano + (1|ID),family = binomial,weights = N_presas,data = Datos)
summary(modelo1OLRE)
drop1(modelo1OLRE, test = "Chisq")
modelo2OLRE <- glmmTMB(prop_aves ~ Region+porc_urbano + (1|ID),family = binomial,weights = N_presas,data = Datos)
drop1(modelo2OLRE, test = "Chisq")
modelo3OLRE <- glmmTMB(prop_aves ~ Region+porc_urbano + (1|ID),family = binomial,weights = N_presas,data = Datos)
drop1(modelo3OLRE, test = "Chisq")
rm(list=ls())
setwd("C:/Users/snpre/Documents/Carrera/Biometria II/tp7")
datos<- read.delim("lenguaje.txt", stringsAsFactors = T)
datos$N_sobrereg
datos$prop_errores<-datos$N_sobrereg/datos$N_verbos_pasado
datos$prop_errores
summary(datos$prop_errores)
library(ggplot2)
ggplot(data=datos, aes(edad, prop_errores)) + geom_point(size=2, aes(color=sexo))
ggplot(data=datos, aes(edad_meses, prop_errores)) + geom_point(size=2, aes(color=sexo))
ggplot(data=datos, aes(edad_meses, prop_errores)) + geom_point(size=2, aes(color=sexo))+geom_smooth(method=lm)
ggplot(data=datos, aes(edad_meses, prop_errores, color=sexo)) + geom_point(size=2, aes(color=sexo))+geom_smooth(method=lm)
ggplot(data=datos, aes(edad_meses, prop_errores, color=sexo)) + geom_point(size=2, aes(color=sexo))+geom_smooth(method=lm)+ labs(title="Proporcion de errores segun edad y sexo")
#3. Genere un modelo de regresión de la ocurrencia de errores de sobre-regularización en función de la edad.
M1 <- glm(prop_errores ~ sexo * edad_meses, family = binomial, weights = N_verbos_pasado, data = Datos)
#3. Genere un modelo de regresión de la ocurrencia de errores de sobre-regularización en función de la edad.
M1 <- glm(prop_errores ~ sexo * edad_meses, family = binomial, weights = N_verbos_pasado, data = datos)
M1b <- glm(cbind(N_sobrereg, (N_verbos_pasado-N_sobrereg)) ~ sexo * edad_meses,family = binomial,data = datos)
AIC(M1,M1b)
# Supuestos
### Analisis de los SUPUESTOS
# A DIFERENCIA DE BERNOULLI, ACA SI CHEQUEAMOS DISPERSION YA NO HYA VR DICOTOMICA!
sum(resid(M1, type="pearson")^2)/M1$df.residual
library(DHARMa)
testDispersion(M1, type = "DHARMa")  # la funcion testDispersion permite setear el calculo del F dispersion (tipo DHARMa o Tipo Pearson -este ultimo es equivalente a sum(resid(M1, type="pearson")^2)/M1$df.residual)
testDispersion(M1, type = "PearsonChisq") # ESTE DA IGUAL AL ORIGINAL, AL QUE HACEMOS A MANO
# Gráficos de res reescalados
sim <- simulateResiduals(fittedMod = M1, plot = T)
# RECHAZO TODO menos outliers. Hay mayor dispersion, no hay distribucion uniforme
# Tambien rechaoz el test KS, no hay bondad de ajuste
plotResiduals(sim, datos$sexo)
plotResiduals(sim, datos$edad_meses)
#3. Genere un modelo de regresión de la ocurrencia de errores de sobre-regularización en función de la edad.
M1 <- glm(prop_errores ~ sexo * edad_meses, family = binomial, weights = N_verbos_pasado, data = datos)
# Supuestos
### Analisis de los SUPUESTOS
# A DIFERENCIA DE BERNOULLI, ACA SI CHEQUEAMOS DISPERSION YA NO HYA VR DICOTOMICA!
sum(resid(M1, type="pearson")^2)/M1$df.residual # 3.445
testDispersion(M1, type = "DHARMa")
testDispersion(M1, type = "PearsonChisq")
# Gráficos de res reescalados
sim <- simulateResiduals(fittedMod = M1, plot = T)
#3. Genere un modelo de regresión de la ocurrencia de errores de sobre-regularización en función de la edad.
M1 <- glm(prop_errores ~ edad_meses, family = binomial, weights = N_verbos_pasado, data = datos)
M1b <- glm(cbind(N_sobrereg, (N_verbos_pasado-N_sobrereg)) ~ edad_meses,family = binomial,data = datos)
AIC(M1,M1b)
# Supuestos
### Analisis de los SUPUESTOS
# A DIFERENCIA DE BERNOULLI, ACA SI CHEQUEAMOS DISPERSION YA NO HYA VR DICOTOMICA!
sum(resid(M1, type="pearson")^2)/M1$df.residual # 3.445
library(DHARMa)
testDispersion(M1, type = "DHARMa")
testDispersion(M1, type = "PearsonChisq")
